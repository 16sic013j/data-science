---
jupyter:
  hide_input: false
  jupytext_format_version: '1.0'
  jupytext_formats: Rmd:rmarkdown
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.6.2
  toc:
    nav_menu: {}
    number_sections: true
    sideBar: true
    skip_h1_title: false
    toc_cell: false
    toc_position: {}
    toc_section_display: block
    toc_window_display: false
---

# Contents
## Introduction and System Setup
- What is Natural Language Processing
    - Unique Challenges in NLP
    - Areas it is used (Spam Filters, Sentiment Analysis, Intent Detection in Digital Assistants)
    - What Problem we are going to Solve (Fake Review Detection)
- Google Colab and GPU Setup
- Installing required Libraries


## Visualizing Data
- Visualize proportion of good vs fake reviews
- Visualize which words are common in good, and fake reviews


## NLP Data Preparation
- Reading Data
- Tokenization
- Lemmatization/Stemming
- Making Bi-Gram and Tri-Grams
- Creating a BOW Representation
- Creating a Tf-Idf Representation

## Making an NLP Classification Model
- Using BOW Representation for Modelling
- Using Tf-Idf Representation for modelling

## Improving by using Word Embeddings
- Word2Vec
- Clustering by PCA in 2D, visualizing if Words in Fake vs Good Reviews are clustered separately
- Using Word2Vec based word embeddings for Modelling

## Improving by Document Embeddings from Word Embeddings
- Doc2Vec
    - Creating Representation using Word2Vec and tf-idf
- Clustering similar to Word2Vec to see if Fake and Good Reviews are separated.
- Using KNN model
- Using a Neural network model

## Other Possible Improvements
- Improving Performace by using LSTM
    - We are only taking the words into account but not their sequence.
- Improving Performance by Transfer Learning
    - We train on other fake review datasets and then use the Neural Networks weights for this Challenge
- Using WordNet for improvement


# References

- https://www.kaggle.com/uciml/sms-spam-collection-dataset
- https://github.com/annaorosz/youtube_spam
- https://www.kaggle.com/benvozza/spam-classification
- https://www.quora.com/What-are-some-good-email-based-data-sets-for-testing-spam-classification-algorithms

```{python ExecuteTime={'end_time': '2018-10-07T09:12:53.479227Z', 'start_time': '2018-10-07T09:12:53.474082Z'}}
# %lsmagic
```

```{python ExecuteTime={'end_time': '2018-10-07T09:13:04.343006Z', 'start_time': '2018-10-07T09:13:04.333963Z'}}
# %magic
```

```{python ExecuteTime={'start_time': '2018-10-08T13:41:35.829053Z', 'end_time': '2018-10-08T13:41:36.125129Z'}}
import pandas as pd
import numpy as np
from IPython.core.display import display
display(pd.DataFrame({"a":[1,2,3],"b":[2,3,4]}))
```

```{python ExecuteTime={'start_time': '2018-10-08T13:41:38.393181Z', 'end_time': '2018-10-08T13:41:38.398259Z'}}
# %autosave 0
```

## Hello

```{python}

```
